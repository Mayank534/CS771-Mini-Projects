{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: \n",
      "train_emoticon_X: 7080 train_emoticon_Y: 7080\n",
      "\n",
      "Test dataset size: \n",
      "test_emoticon_X: 2232\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read emoticon dataset\n",
    "train_emoticon_df = pd.read_csv(\"datasets/train/train_emoticon.csv\")\n",
    "train_emoticon_X = train_emoticon_df['input_emoticon'].tolist()\n",
    "train_emoticon_Y = train_emoticon_df['label'].tolist()\n",
    "\n",
    "test_emoticon_X = pd.read_csv(\"datasets/test/test_emoticon.csv\")['input_emoticon'].tolist()\n",
    "\n",
    "test_feat_X = np.load(\"datasets/test/test_feature.npz\", allow_pickle=True)['features']\n",
    "\n",
    "\n",
    "print(f\"Train dataset size: \")\n",
    "print(f\"train_emoticon_X: {len(train_emoticon_X)} train_emoticon_Y: {len(train_emoticon_Y)}\")\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Test dataset size: \")\n",
    "print(f\"test_emoticon_X: {len(test_emoticon_X)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset size: \n",
      "valid_emoticon_X: 489 valid_emoticon_Y: 489\n",
      "\n",
      "Test dataset size: \n",
      "test_emoticon_X: 2232\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read emoticon dataset\n",
    "valid_emoticon_df = pd.read_csv(\"datasets/valid/valid_emoticon.csv\")\n",
    "valid_emoticon_X = valid_emoticon_df['input_emoticon'].tolist()\n",
    "valid_emoticon_Y = valid_emoticon_df['label'].tolist()\n",
    "\n",
    "test_emoticon_X = pd.read_csv(\"datasets/test/test_emoticon.csv\")['input_emoticon'].tolist()\n",
    "\n",
    "\n",
    "print(f\"Validation dataset size: \")\n",
    "print(f\"valid_emoticon_X: {len(valid_emoticon_X)} valid_emoticon_Y: {len(valid_emoticon_Y)}\")\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Test dataset size: \")\n",
    "print(f\"test_emoticon_X: {len(test_emoticon_X)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Encoded Train Emoticon Data:  [[2 9 4 0 3 5 6 8 1 7 0 6 3]\n",
      " [9 0 3 1 8 5 2 7 0 5 4 2 6]]\n",
      "Sample Encoded Test Emoticon Data:  [array([ 9,  2,  0,  4,  8, -1, -1,  1,  5,  4, -1,  0,  2]), array([ 2, -1,  9, -1,  1,  4,  8,  0,  5,  2, -1,  0,  4])]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 4. Label Encoding for Emoticon Dataset\n",
    "# Flatten emoticons (split each string into individual characters)\n",
    "train_emoticon_X_flattened = [list(emoticon) for emoticon in train_emoticon_X]\n",
    "test_emoticon_X_flattened = [list(emoticon) for emoticon in test_emoticon_X]\n",
    "\n",
    "# Initialize label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode each emoticon character into integers for training data\n",
    "train_emoticon_X_encoded = [label_encoder.fit_transform(emoticon) for emoticon in train_emoticon_X_flattened]\n",
    "def safe_transform(emoticon, label_encoder):\n",
    "    # Get the classes learned by the LabelEncoder\n",
    "    known_classes = set(label_encoder.classes_)\n",
    "    \n",
    "    # Return transformed values, and map unseen labels to -1\n",
    "    return np.array([label_encoder.transform([char])[0] if char in known_classes else -1 for char in emoticon])\n",
    "\n",
    "# Apply safe transformation on the test data\n",
    "test_emoticon_X_encoded = [safe_transform(emoticon, label_encoder) for emoticon in test_emoticon_X_flattened]\n",
    "# Convert to NumPy arrays for model training\n",
    "train_emoticon_X_encoded = np.array(train_emoticon_X_encoded)\n",
    "# test_emoticon_X_encoded = np.array(test_emoticon_X_encoded)\n",
    "\n",
    "# Verify that the emoticon data is encoded\n",
    "print(\"\\nSample Encoded Train Emoticon Data: \", train_emoticon_X_encoded[:2])\n",
    "print(\"Sample Encoded Test Emoticon Data: \", test_emoticon_X_encoded[:2])\n",
    "\n",
    "# Now, your datasets `train_emoticon_X_encoded`, `train_seq_X`, and `train_feat_X` are ready for training models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Encoded Valid Emoticon Data:  [[8 2 1 0 3 7 4 9 5 0 3 4 6]\n",
      " [9 3 4 2 6 5 1 8 1 5 3 7 0]]\n",
      "Sample Encoded Test Emoticon Data:  [array([ 9,  4,  2,  5,  8, -1, -1,  3,  6,  5, -1,  2,  4]), array([ 4, -1,  9, -1,  3,  5,  8,  2,  6,  4, -1,  2,  5])]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# 4. Label Encoding for Emoticon Dataset\n",
    "# Flatten emoticons (split each string into individual characters)\n",
    "valid_emoticon_X_flattened = [list(emoticon) for emoticon in valid_emoticon_X]\n",
    "\n",
    "# Initialize label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode each emoticon character into integers for training data\n",
    "valid_emoticon_X_encoded = [label_encoder.fit_transform(emoticon) for emoticon in valid_emoticon_X_flattened]\n",
    "\n",
    "def safe_transform(emoticon, label_encoder):\n",
    "    # Get the classes learned by the LabelEncoder\n",
    "    known_classes = set(label_encoder.classes_)\n",
    "    \n",
    "    # Return transformed values, and map unseen labels to -1\n",
    "    return np.array([label_encoder.transform([char])[0] if char in known_classes else -1 for char in emoticon])\n",
    "\n",
    "# Apply safe transformation on the test data\n",
    "test_emoticon_X_encoded = [safe_transform(emoticon, label_encoder) for emoticon in test_emoticon_X_flattened]\n",
    "\n",
    "# Convert to NumPy arrays for model training\n",
    "valid_emoticon_X_encoded = np.array(valid_emoticon_X_encoded)\n",
    "\n",
    "# Verify that the emoticon data is encoded\n",
    "print(\"\\nSample Encoded Valid Emoticon Data: \", valid_emoticon_X_encoded[:2])\n",
    "print(\"Sample Encoded Test Emoticon Data: \", test_emoticon_X_encoded[:2])\n",
    "\n",
    "# Now, your datasets `valid_emoticon_X_encoded`, `valid_seq_X`, and `valid_feat_X` are ready for training models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# # Initialize the TF-IDF vectorizer\n",
    "# tfidf_vectorizer = TfidfVectorizer(max_features=400)  # max_features limits the number of features\n",
    "\n",
    "# # Fit and transform on the training text sequences\n",
    "# train_seq_X_tfidf = tfidf_vectorizer.fit_transform(train_seq_X).toarray()\n",
    "\n",
    "# # Transform the test text sequences\n",
    "# test_seq_X_tfidf = tfidf_vectorizer.transform(test_seq_X).toarray()\n",
    "\n",
    "# print(f\"TF-IDF train shape: {train_seq_X_tfidf.shape}\")\n",
    "# print(f\"TF-IDF test shape: {test_seq_X_tfidf.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# # Initialize the TF-IDF vectorizer\n",
    "# tfidf_vectorizer = TfidfVectorizer(max_features=500)  # max_features limits the number of features\n",
    "\n",
    "# Fit and transform on the training text sequences\n",
    "# valid_seq_X_tfidf = tfidf_vectorizer.fit_transform(valid_seq_X).toarray()\n",
    "\n",
    "\n",
    "\n",
    "# print(f\"TF-IDF valid shape: {valid_seq_X_tfidf.shape}\")\n",
    "# print(f\"TF-IDF test shape: {test_seq_X_tfidf.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_feat_X_flattened = train_feat_X.reshape(train_feat_X.shape[0], -1)  # Shape will be (7080, 13 * 768)\n",
    "# test_feat_X_flattened = test_feat_X.reshape(test_feat_X.shape[0], -1)  # Adjust for test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_feat_X_flattened = valid_feat_X.reshape(valid_feat_X.shape[0], -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_emoticon_X_encoded shape: (7080, 13)\n",
      "valid_emoticon_X_encoded shape: (489, 13)\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_emoticon_X_encoded shape: {train_emoticon_X_encoded.shape}\")\n",
    "# print(f\"train_seq_X_tfidf shape: {train_seq_X_tfidf.shape}\")\n",
    "# print(f\"train_feat_X shape: {train_feat_X.shape}\")\n",
    "print(f\"valid_emoticon_X_encoded shape: {valid_emoticon_X_encoded.shape}\")\n",
    "# print(f\"valid_seq_X_tfidf shape: {valid_seq_X_tfidf.shape}\")\n",
    "# print(f\"valid_feat_X shape: {valid_feat_X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emoticon training data shape: (7080, 13)\n",
      "Emoticon valid data shape: (489, 13)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Emoticon training data shape: {train_emoticon_X_encoded.shape}\")\n",
    "# print(f\"Sequence training data shape: {train_seq_X_tfidf.shape}\")\n",
    "# print(f\"Feature training data shape: {train_feat_X_flattened.shape}\")\n",
    "print(f\"Emoticon valid data shape: {valid_emoticon_X_encoded.shape}\")\n",
    "# print(f\"Sequence valid data shape: {valid_seq_X_tfidf.shape}\")\n",
    "# print(f\"Feature valid data shape: {valid_feat_X_flattened.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all features for training\n",
    "# train_X_combined = np.hstack([train_emoticon_X_encoded, train_seq_X_tfidf, train_feat_X_flattened])\n",
    "\n",
    "# # Combine all features for testing\n",
    "# test_X_combined = np.hstack([test_emoticon_X_encoded, test_seq_X_tfidf, test_feat_X_flattened])\n",
    "\n",
    "# print(f\"Combined train shape: {train_X_combined.shape}\")  # Should be (7080, 10497)\n",
    "# print(f\"Combined test shape: {test_X_combined.shape}\")\n",
    "train_X_combined=train_emoticon_X_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined valid shape: (489, 13)\n"
     ]
    }
   ],
   "source": [
    "# valid_X_combined = np.hstack([valid_emoticon_X_encoded, valid_seq_X_tfidf, valid_feat_X_flattened])\n",
    "valid_X_combined = valid_emoticon_X_encoded\n",
    "print(f\"Combined valid shape: {valid_X_combined.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7080\n",
      "489\n"
     ]
    }
   ],
   "source": [
    "print(len(train_emoticon_Y))\n",
    "# print(len(train_feat_Y))\n",
    "print(len(valid_emoticon_Y))\n",
    "# print(len(valid_feat_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train combined shape: (7080, 13)\n",
      "Valid combined shape: (489, 13)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train combined shape: {train_X_combined.shape}\")\n",
    "print(f\"Valid combined shape: {valid_X_combined.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_emoticon_df = pd.read_csv(\"datasets/test/test_emoticon.csv\")\n",
    "# test_emoticon_Y= test_emoticon_df['label'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating for n_clusters=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for n_clusters=1: 51.7382%\n",
      "Evaluating for n_clusters=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for n_clusters=2: 50.9202%\n",
      "Evaluating for n_clusters=3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for n_clusters=3: 48.4663%\n",
      "Evaluating for n_clusters=4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for n_clusters=4: 49.6933%\n",
      "Evaluating for n_clusters=5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for n_clusters=5: 49.0798%\n",
      "Evaluating for n_clusters=6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for n_clusters=6: 52.5562%\n",
      "Evaluating for n_clusters=7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for n_clusters=7: 51.5337%\n",
      "Evaluating for n_clusters=8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for n_clusters=8: 51.1247%\n",
      "Evaluating for n_clusters=9...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for n_clusters=9: 50.7157%\n",
      "Evaluating for n_clusters=10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for n_clusters=10: 44.9898%\n",
      "\n",
      "Best n_clusters: 6 with accuracy: 52.5562%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Accuracy: 52.5562%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import numpy as np\n",
    "\n",
    "# Use valid_emoticon_Y as valid_Y\n",
    "valid_Y = valid_emoticon_Y\n",
    "\n",
    "# Step 1: Create Prototypes using KMeans\n",
    "def create_prototypes_kmeans(X, Y, n_clusters=1):\n",
    "    unique_classes = np.unique(Y)\n",
    "    prototypes = {}\n",
    "    \n",
    "    for cls in unique_classes:\n",
    "        # Get all samples for the current class\n",
    "        class_samples = X[np.array(Y) == cls]\n",
    "        \n",
    "        # Use KMeans to create clusters within the class (prototypes)\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        kmeans.fit(class_samples)\n",
    "        \n",
    "        # Store the cluster centers (prototypes) for this class\n",
    "        prototypes[cls] = kmeans.cluster_centers_\n",
    "    \n",
    "    return prototypes\n",
    "\n",
    "# Step 2: Classify Data using Prototypes\n",
    "def classify_with_prototypes(X, prototypes):\n",
    "    predictions = []\n",
    "    \n",
    "    for x in X:\n",
    "        # Calculate distances to all prototypes\n",
    "        distances = {}\n",
    "        \n",
    "        for cls, proto_list in prototypes.items():\n",
    "            # For each prototype in the class\n",
    "            distances[cls] = min([euclidean_distances([x], [proto])[0][0] for proto in proto_list])\n",
    "        \n",
    "        # Assign the class with the closest prototype\n",
    "        predicted_class = min(distances, key=distances.get)\n",
    "        predictions.append(predicted_class)\n",
    "    \n",
    "    return np.array(predictions)\n",
    "\n",
    "# Step 3: Iterate through the unique classes in the validation dataset\n",
    "unique_classes = np.unique(valid_Y)\n",
    "# Iterate through different values of n_clusters to find the best one\n",
    "best_n_clusters = None\n",
    "best_accuracy = 0\n",
    "\n",
    "# Try different values for n_clusters\n",
    "for n_clusters in range(1, 11):  # Adjust the range as needed\n",
    "    print(f\"Evaluating for n_clusters={n_clusters}...\")\n",
    "    \n",
    "    # Step 1: Create Prototypes using current n_clusters\n",
    "    prototypes_valid = create_prototypes_kmeans(train_X_combined, train_emoticon_Y, n_clusters=n_clusters)\n",
    "    \n",
    "    # Step 2: Classify Validation Data using the prototypes\n",
    "    valid_predictions = classify_with_prototypes(valid_X_combined, prototypes_valid)\n",
    "    \n",
    "    # Step 3: Evaluate Accuracy on Validation Dataset\n",
    "    valid_accuracy = np.mean(valid_predictions == valid_Y)\n",
    "    \n",
    "    print(f\"Validation Accuracy for n_clusters={n_clusters}: {valid_accuracy * 100:.4f}%\")\n",
    "    \n",
    "    # Step 4: If this n_clusters gives a better accuracy, store it\n",
    "    if valid_accuracy > best_accuracy:\n",
    "        best_accuracy = valid_accuracy\n",
    "        best_n_clusters = n_clusters\n",
    "\n",
    "# Once best_n_clusters is found, use it to create prototypes and classify test data\n",
    "print(f\"\\nBest n_clusters: {best_n_clusters} with accuracy: {best_accuracy * 100:.4f}%\")\n",
    "\n",
    "# Step 5: Create Prototypes using the best n_clusters for the full dataset (train + valid combined, or train alone)\n",
    "prototypes_best = create_prototypes_kmeans(train_X_combined, train_emoticon_Y, n_clusters=best_n_clusters)\n",
    "\n",
    "# Step 6: Classify Validation Data with the best n_clusters\n",
    "valid_predictions = classify_with_prototypes(valid_X_combined, prototypes_best)\n",
    "\n",
    "# Step 7: Final Evaluation\n",
    "valid_accuracy_final = np.mean(valid_predictions == valid_Y)\n",
    "print(f\"Final Validation Accuracy: {valid_accuracy_final * 100:.4f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
      "[1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0\n",
      " 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0\n",
      " 1 0 1 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1\n",
      " 0 1 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 1 0 0 1 1 1 1 0 0 1 0 0 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 0 1 0 1 1 1 1 1 0 1 0 1 0 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 0\n",
      " 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 0 1 0 0 0 1 1 0 1 0 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 1\n",
      " 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 0 0 0 1 1\n",
      " 0 0 1 1 0 0 0 0 1 1 1 0 0 0 1 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 1\n",
      " 1 0 1 1 1 1 0 1 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0\n",
      " 1 1 1 0 0 1 1 1 0 1 1 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 1 0 1 1 0\n",
      " 1 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 0 1 1 1 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(valid_Y)\n",
    "print(valid_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
